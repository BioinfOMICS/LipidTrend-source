<!DOCTYPE html><html><head><title>R: Plot of regularized linear discriminant functions for...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script>
const macros = { "\\R": "\\textsf{R}", "\\mbox": "\\text", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R.css">
</head><body><div class="container"><main>

<table style="width: 100%;"><tr><td>plotRLDF {limma}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Plot of regularized linear discriminant functions for microarray data</h2>

<h3>Description</h3>

<p>Plot regularized linear discriminant functions for classifying samples based on expression data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRLDF(y, design = NULL, z = NULL, nprobes = 100, plot = TRUE,
         labels.y = NULL, labels.z = NULL, pch.y = NULL, pch.z = NULL,
         col.y = "black", col.z = "black",
         show.dimensions = c(1,2), ndim = max(show.dimensions),
         var.prior = NULL, df.prior = NULL, trend = FALSE, robust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="y">y</code></td>
<td>
<p>the training dataset. Can be any data object which can be coerced to a matrix, such as <code>ExpressionSet</code> or <code>EList</code>.</p>
</td></tr>
<tr><td><code id="design">design</code></td>
<td>
<p>design matrix defining the training groups to be distinguished. The first column is assumed to represent the intercept.
Defaults to <code>model.matrix(~factor(labels.y))</code>.</p>
</td></tr>
<tr><td><code id="z">z</code></td>
<td>
<p>the dataset to be classified.  Can be any data object which can be coerced to a matrix, such as <code>ExpressionSet</code> or <code>EList</code>.  Rows must correspond to rows of <code>y</code>.</p>
</td></tr>
<tr><td><code id="nprobes">nprobes</code></td>
<td>
<p>number of probes to be used for the calculations. The probes will be selected by moderated F statistic.</p>
</td></tr>
<tr><td><code id="plot">plot</code></td>
<td>
<p>logical, should a plot be created?</p>
</td></tr>
<tr><td><code id="labels.y">labels.y</code></td>
<td>
<p>character vector of sample names or labels in <code>y</code>. Defaults to <code>colnames(y)</code> or failing that to <code>1:n</code>.</p>
</td></tr>
<tr><td><code id="labels.z">labels.z</code></td>
<td>
<p>character vector of sample names or labels in <code>z</code>. Defaults to <code>colnames(z)</code> or failing that to <code>letters[1:n]</code>.</p>
</td></tr>
<tr><td><code id="pch.y">pch.y</code></td>
<td>
<p>plotting symbol or symbols for <code>y</code>. See <code><a href="../../graphics/html/points.html">points</a></code> for possible values. Takes precedence over <code>labels.y</code> if both are specified.</p>
</td></tr>
<tr><td><code id="pch.z">pch.z</code></td>
<td>
<p>plotting symbol or symbols for <code>y</code>. See <code><a href="../../graphics/html/points.html">points</a></code> for possible values. Takes precedence over <code>labels.z</code> if both are specified.</p>
</td></tr>
<tr><td><code id="col.y">col.y</code></td>
<td>
<p>colors for the plotting <code>labels.y</code>.</p>
</td></tr>
<tr><td><code id="col.z">col.z</code></td>
<td>
<p>colors for the plotting <code>labels.z</code>.</p>
</td></tr>
<tr><td><code id="show.dimensions">show.dimensions</code></td>
<td>
<p>integer vector of length two indicating which two discriminant functions to plot. Functions are in decreasing order of discriminatory power.</p>
</td></tr>
<tr><td><code id="ndim">ndim</code></td>
<td>
<p>number of discriminant functions to compute</p>
</td></tr>
<tr><td><code id="var.prior">var.prior</code></td>
<td>
<p>prior variances, for regularizing the within-group covariance matrix. By default is estimated by <code>squeezeVar</code>.</p>
</td></tr>
<tr><td><code id="df.prior">df.prior</code></td>
<td>
<p>prior degrees of freedom for regularizing the within-group covariance matrix. By default is estimated by <code>squeezeVar</code>.</p>
</td></tr>
<tr><td><code id="trend">trend</code></td>
<td>
<p>logical, should a trend be estimated for <code>var.prior</code>?  See <code>eBayes</code> for details.  Only used if <code>var.prior</code> or <code>df.prior</code> are <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="robust">robust</code></td>
<td>
<p>logical, should <code>var.prior</code> and <code>df.prior</code> be estimated robustly?  See <code>eBayes</code> for details.  Only used if <code>var.prior</code> or <code>df.prior</code> are <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="...">...</code></td>
<td>
<p>any other arguments are passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function builds discriminant functions from the training data (<code>y</code>) and applies them to the test data (<code>z</code>).
The method is a variation on classifical linear discriminant functions (LDFs), in that the within-group covariance matrix is regularized to ensure that it is invertible, with eigenvalues bounded away from zero.
The within-group covariance matrix is squeezed towards a diagonal matrix with empirical Bayes posterior variances as diagonal elements.
</p>
<p>The calculations are based on a filtered list of probes.
The <code>nprobes</code> probes with largest moderated F statistics are used to discriminate.
</p>
<p>The <code>ndim</code> argument allows all required LDFs to be computed even though only two are plotted.
</p>


<h3>Value</h3>

<p>If <code>plot=TRUE</code> a plot is created on the current graphics device.
A list containing the following components is (invisibly) returned:
</p>
<table role = "presentation">
<tr><td><code>training</code></td>
<td>
<p>numeric matrix with <code>ncol(y)</code> rows and <code>ndim</code> columns containing discriminant functions evaluated for the training data.</p>
</td></tr>
<tr><td><code>predicting</code></td>
<td>
<p>numeric matrix with <code>ncol(z)</code> rows and <code>ndim</code> columns containing discriminant functions evalulated on the classification data.</p>
</td></tr>
<tr><td><code>top</code></td>
<td>
<p>integer vector of length <code>nprobes</code> giving indices of probes used.</p>
</td></tr>
<tr><td><code>metagenes</code></td>
<td>
<p>numeric matrix with <code>nprobes</code> rows and <code>ndim</code> columns containing probe weights defining each discriminant function.</p>
</td></tr>
<tr><td><code>singular.values</code></td>
<td>
<p>singular.values showing the predictive power of each discriminant function.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>maximum number of discriminant functions with singular.values greater than zero.</p>
</td></tr>
<tr><td><code>var.prior</code></td>
<td>
<p>numeric vector of prior variances.</p>
</td></tr>
<tr><td><code>df.prior</code></td>
<td>
<p>numeric vector of prior degrees of freedom.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The default values for <code>df.prior</code> and <code>var.prior</code> were changed in limma 3.27.10.
Previously these were preset values.
Now the default is to estimate them using <code>squeezeVar</code>.
</p>


<h3>Author(s)</h3>

<p>Gordon Smyth, Di Wu and Yifang Hu</p>


<h3>See Also</h3>

<p><code>lda</code> in package <code>MASS</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate gene expression data for 1000 probes and 6 microarrays.
# Samples are in two groups
# First 50 probes are differentially expressed in second group
sd &lt;- 0.3*sqrt(4/rchisq(1000,df=4))
y &lt;- matrix(rnorm(1000*6,sd=sd),1000,6)
rownames(y) &lt;- paste("Gene",1:1000)
y[1:50,4:6] &lt;- y[1:50,4:6] + 2

z &lt;- matrix(rnorm(1000*6,sd=sd),1000,6)
rownames(z) &lt;- paste("Gene",1:1000)
z[1:50,4:6] &lt;- z[1:50,4:6] + 1.8
z[1:50,1:3] &lt;- z[1:50,1:3] - 0.2

design &lt;- cbind(Grp1=1,Grp2vs1=c(0,0,0,1,1,1))
options(digit=3)

# Samples 1-6 are training set, samples a-f are test set:
plotRLDF(y, design, z=z, col.y="black", col.z="red")
legend("top", pch=16, col=c("black","red"), legend=c("Training","Predicted"))
</code></pre>

<hr><div style="text-align: center;">[Package <em>limma</em> version 3.66.0 <a href="00Index.html">Index</a>]</div></main>

</div>
</body></html>
